# 韩小博 模式识别作业
## 1. 朴素贝叶斯（Naive Bayes）用于分类
### 1.1 贝叶斯公式
&emsp;&emsp;朴素贝叶斯方法是一组基于应用贝叶斯定理的监督学习算法，在给定类变量值的情况下，每对特征之间的条件独立性的“朴素”假设  
贝叶斯公式： 
 $$P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)} \tag{1}$$
- $P(X|Y)P(Y)=P(Y|X)P(X)=P(Y,X)$  
- $P(Y)$：先验概率  
- $P(Y|X)$：后验概率 
- $P(Y,X)$：联合概率密度  
### 1.2 贝叶斯方法 
&emsp;&emsp;机器学习的最终目的就是回归 or 分类，这里二者都可以理解为预测，回归很好理解，分类也可以理解为预测属于某一类的概率是多少。 我们把上述贝叶斯公式中的X理解为“具有某特征”，把Y理解成“类别标签”，那么贝叶斯公式就可以表示为：
$$P(属于某类|具有某特征)=\frac{P(具有某特征|属于某类)P(属于某类)}{P(具有某特征)}\tag{2}$$
&emsp;&emsp;贝叶斯方法把计算“具有某特征条件下属于某类（就是分类）”的概率转化为需要计算“属于某类条件下具有某特征（分别训练模型）”的概率，属于有监督学习。
### 1.3 朴素贝叶斯
&emsp;&emsp; 应用垃圾邮件识别的案例引出朴素贝叶斯： 
- 判断 $P(垃圾邮件|具有某特征)$ 是否> $1/2$
- 训练集：垃圾邮件和正常邮件各1万封
- 判断以下是否为垃圾邮件：“我司可办理正规发票（保真）17%增值税发票点数优惠！”
&emsp;&emsp;首先进行分词，也就是把一整句话拆分成更细粒度的词语来表示：  
“我”，“司”，“可”，“办理”，“正规发票”，“保真”，“增值税”，“发票”，“点数”，“优惠”  
分词之后的贝叶斯公式：  
$$P(垃圾邮件|(我，司，可，办理，正规发票，保真，增值税，发票，点数，优惠 ))=\frac{P((我，司，可，办理，正规发票，保真，增值税，发票，点数，优惠 )|垃圾邮件)P(垃圾邮件)}{P(我，司，可，办理，正规发票，保真，增值税，发票，点数，优惠 )}$$  
$$P(正常邮件|(我，司，可，办理，正规发票，保真，增值税，发票，点数，优惠 ))=\frac{P((我，司，可，办理，正规发票，保真，增值税，发票，点数，优惠 )|垃圾邮件)P(正常邮件)}{P(我，司，可，办理，正规发票，保真，增值税，发票，点数，优惠 )}$$
&emsp;&emsp;贝叶斯方法把计算“具有某特征条件下属于某类（就是分类）”的概率转化为需要计算“属于某类条件下具有某特征（分别训练模型）”的概率，属于有监督学习。 也就是说，我们现在要计算的是：正常邮件 or 垃圾邮件中具有上述那些词语的概率。
#### 1.3.1 条件独立性假设
&emsp;&emsp;朴素近似是把求某一类邮件中包含上述那些词语的概率等同于某一类邮件中包含每一种词语概率的乘积！！这其实就是朴素贝叶斯的实质，也是条件独立假设的实质。
$$P(我，司，可，办理，正规发票，保真，增值税，发票，点数，优惠|S)=P(我|S)P(司|S)P(可|S)P(办理|S)P(正规发票|S)P(保真|S)P(增值税|S)P(发票|S)P(点数|S)P(发票|S)P(优惠|S)$$
- $其中，P(发票|S)= \frac{垃圾邮件中所有“发票”的次数}{垃圾邮件中所有词语的次数}$
#### 1.3.2 朴素贝叶斯的特征
- 加上条件独立假设的贝叶斯方法就是朴素贝叶斯方法（Naive Bayes）  
- 由于乘法交换律，朴素贝叶斯中算出来交换词语顺序的条件概率完全一样
